package main

import (
	"encoding/json"
	"fmt"
	"math/rand"
	"os"
	"runtime"
	"strings"
	"sync"
	"time"
)

// OperationStats przechowuje statystyki pojedynczej operacji
type OperationStats struct {
	Comparisons    int `json:"comparisons"`
	PointerUpdates int `json:"pointer_updates"`
	Height         int `json:"height"`
}

// TestResult przechowuje wyniki testu dla konkretnego n
type TestResult struct {
	N                    int              `json:"n"`
	TestNumber           int              `json:"test_number"`
	Scenario             string           `json:"scenario"`
	InsertOperations     []OperationStats `json:"insert_operations"`
	DeleteOperations     []OperationStats `json:"delete_operations"`
	InsertAvgComparisons float64          `json:"insert_avg_comparisons"`
	InsertMaxComparisons int              `json:"insert_max_comparisons"`
	InsertAvgPointers    float64          `json:"insert_avg_pointers"`
	InsertMaxPointers    int              `json:"insert_max_pointers"`
	InsertAvgHeight      float64          `json:"insert_avg_height"`
	InsertMaxHeight      int              `json:"insert_max_height"`
	DeleteAvgComparisons float64          `json:"delete_avg_comparisons"`
	DeleteMaxComparisons int              `json:"delete_max_comparisons"`
	DeleteAvgPointers    float64          `json:"delete_avg_pointers"`
	DeleteMaxPointers    int              `json:"delete_max_pointers"`
	DeleteAvgHeight      float64          `json:"delete_avg_height"`
	DeleteMaxHeight      int              `json:"delete_max_height"`
	TotalTime            float64          `json:"total_time_ms"`
}

// AllResults przechowuje wszystkie wyniki test√≥w
type AllResults struct {
	OrderedResults []TestResult `json:"ordered_results"`
	RandomResults  []TestResult `json:"random_results"`
	Summary        Summary      `json:"summary"`
}

// Summary przechowuje podsumowanie wynik√≥w
type Summary struct {
	OrderedScenario ScenarioSummary `json:"ordered_scenario"`
	RandomScenario  ScenarioSummary `json:"random_scenario"`
}

// ScenarioSummary przechowuje ≈õrednie dla scenariusza
type ScenarioSummary struct {
	AvgResults []NSummary `json:"avg_results"`
}

// NSummary przechowuje ≈õrednie dla konkretnego n
type NSummary struct {
	N                    int     `json:"n"`
	AvgInsertComparisons float64 `json:"avg_insert_comparisons"`
	AvgInsertPointers    float64 `json:"avg_insert_pointers"`
	AvgInsertHeight      float64 `json:"avg_insert_height"`
	AvgDeleteComparisons float64 `json:"avg_delete_comparisons"`
	AvgDeletePointers    float64 `json:"avg_delete_pointers"`
	AvgDeleteHeight      float64 `json:"avg_delete_height"`
	AvgTotalTime         float64 `json:"avg_total_time_ms"`
}

// AveragedResult przechowuje u≈õrednione wyniki dla konkretnego n i scenariusza
type AveragedResult struct {
	N                    int     `json:"n"`
	Scenario             string  `json:"scenario"`
	AvgInsertComparisons float64 `json:"avg_insert_comparisons"`
	AvgInsertPointers    float64 `json:"avg_insert_pointers"`
	AvgInsertHeight      float64 `json:"avg_insert_height"`
	AvgDeleteComparisons float64 `json:"avg_delete_comparisons"`
	AvgDeletePointers    float64 `json:"avg_delete_pointers"`
	AvgDeleteHeight      float64 `json:"avg_delete_height"`
	AvgTotalTime         float64 `json:"avg_total_time_ms"`
}

// AveragedResults przechowuje skr√≥cone wyniki
type AveragedResults struct {
	AveragedResults []AveragedResult `json:"averaged_results"`
}

// TestTask reprezentuje zadanie testowe do wykonania w worker pool
type TestTask struct {
	N       int
	TestNum int
	Ordered bool
	Seed    int64
}

// ProgressInfo zawiera informacje o postƒôpie
type ProgressInfo struct {
	Completed   int
	Total       int
	CurrentN    int
	Scenario    string
	WorkerCount int
}

// createPermutationThreadSafe tworzy losowƒÖ permutacjƒô z w≈Çasnym generatorem (thread-safe)
func createPermutationThreadSafe(n int, seed int64) []int {
	perm := make([]int, n)
	for i := 0; i < n; i++ {
		perm[i] = i + 1
	}

	// U≈ºywamy lokalnego generatora z konkretnym seed dla powtarzalno≈õci
	localRand := rand.New(rand.NewSource(seed))
	localRand.Shuffle(len(perm), func(i, j int) {
		perm[i], perm[j] = perm[j], perm[i]
	})

	return perm
}

// runSingleTestThreadSafe wykonuje pojedynczy test w spos√≥b thread-safe
func runSingleTestThreadSafe(task TestTask) TestResult {
	startTime := time.Now()

	scenario := "random"
	if task.Ordered {
		scenario = "ordered"
	}

	result := TestResult{
		N:                task.N,
		TestNumber:       task.TestNum,
		Scenario:         scenario,
		InsertOperations: make([]OperationStats, 0, task.N),
		DeleteOperations: make([]OperationStats, 0, task.N),
	}

	bst := BST{}

	// Przygotowanie sekwencji do wstawiania
	var insertSequence []int
	if task.Ordered {
		insertSequence = make([]int, task.N)
		for i := 0; i < task.N; i++ {
			insertSequence[i] = i + 1
		}
	} else {
		insertSequence = createPermutationThreadSafe(task.N, task.Seed)
	}

	// Wstawianie element√≥w
	for _, key := range insertSequence {
		prevComparisons := bst.comparisons
		prevPointers := bst.pointerUpdates

		bst.insert(key)
		height := bst.heightOfTree()

		opStats := OperationStats{
			Comparisons:    bst.comparisons - prevComparisons,
			PointerUpdates: bst.pointerUpdates - prevPointers,
			Height:         height,
		}

		result.InsertOperations = append(result.InsertOperations, opStats)
	}

	// Przygotowanie sekwencji do usuwania (zawsze losowa)
	deleteSequence := createPermutationThreadSafe(task.N, task.Seed+1000)

	// Reset statystyk dla operacji usuwania
	bst.resetStats()

	// Usuwanie element√≥w
	for _, key := range deleteSequence {
		prevComparisons := bst.comparisons
		prevPointers := bst.pointerUpdates

		bst.deleteNode(key)
		height := bst.heightOfTree()

		opStats := OperationStats{
			Comparisons:    bst.comparisons - prevComparisons,
			PointerUpdates: bst.pointerUpdates - prevPointers,
			Height:         height,
		}

		result.DeleteOperations = append(result.DeleteOperations, opStats)
	}

	// Obliczanie statystyk
	result.calculateStats()
	result.TotalTime = float64(time.Since(startTime).Nanoseconds()) / 1e6 // w milisekundach

	return result
}

// calculateStats oblicza ≈õrednie i maksymalne warto≈õci
func (tr *TestResult) calculateStats() {
	// Statystyki wstawiania
	if len(tr.InsertOperations) > 0 {
		totalComp, totalPtr, totalHeight := 0, 0, 0
		maxComp, maxPtr, maxHeight := 0, 0, 0

		for _, op := range tr.InsertOperations {
			totalComp += op.Comparisons
			totalPtr += op.PointerUpdates
			totalHeight += op.Height

			if op.Comparisons > maxComp {
				maxComp = op.Comparisons
			}
			if op.PointerUpdates > maxPtr {
				maxPtr = op.PointerUpdates
			}
			if op.Height > maxHeight {
				maxHeight = op.Height
			}
		}

		n := len(tr.InsertOperations)
		tr.InsertAvgComparisons = float64(totalComp) / float64(n)
		tr.InsertMaxComparisons = maxComp
		tr.InsertAvgPointers = float64(totalPtr) / float64(n)
		tr.InsertMaxPointers = maxPtr
		tr.InsertAvgHeight = float64(totalHeight) / float64(n)
		tr.InsertMaxHeight = maxHeight
	}

	// Statystyki usuwania
	if len(tr.DeleteOperations) > 0 {
		totalComp, totalPtr, totalHeight := 0, 0, 0
		maxComp, maxPtr, maxHeight := 0, 0, 0

		for _, op := range tr.DeleteOperations {
			totalComp += op.Comparisons
			totalPtr += op.PointerUpdates
			totalHeight += op.Height

			if op.Comparisons > maxComp {
				maxComp = op.Comparisons
			}
			if op.PointerUpdates > maxPtr {
				maxPtr = op.PointerUpdates
			}
			if op.Height > maxHeight {
				maxHeight = op.Height
			}
		}

		n := len(tr.DeleteOperations)
		tr.DeleteAvgComparisons = float64(totalComp) / float64(n)
		tr.DeleteMaxComparisons = maxComp
		tr.DeleteAvgPointers = float64(totalPtr) / float64(n)
		tr.DeleteMaxPointers = maxPtr
		tr.DeleteAvgHeight = float64(totalHeight) / float64(n)
		tr.DeleteMaxHeight = maxHeight
	}
}

// runBenchmark przeprowadza wszystkie testy
func runBenchmark() AllResults {
	results := AllResults{
		OrderedResults: make([]TestResult, 0),
		RandomResults:  make([]TestResult, 0),
	}

	// Konfiguracja wielowƒÖtkowo≈õci - ustaw tutaj liczbƒô wƒÖtk√≥w
	numWorkers := 4 // Mo≈ºna zmieniƒá tƒô warto≈õƒá (np. 4, 8, 16)
	if numWorkers > runtime.NumCPU() {
		numWorkers = runtime.NumCPU()
	}

	// Warto≈õci n do testowania
	nValues := []int{10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000}
	testsPerN := 20

	fmt.Println("üöÄ Rozpoczynam wielowƒÖtkowe testy wydajno≈õci BST...")
	fmt.Printf("ÔøΩ Liczba wƒÖtk√≥w roboczych: %d (z %d dostƒôpnych rdzeni)\n", numWorkers, runtime.NumCPU())
	fmt.Printf("ÔøΩ Warto≈õci n: %v\n", nValues)
	fmt.Printf("üîÑ Liczba test√≥w dla ka≈ºdego n: %d\n", testsPerN)
	fmt.Println()

	totalTests := len(nValues) * testsPerN * 2 // 2 scenariusze
	fmt.Printf("üìà ≈ÅƒÖczna liczba test√≥w do wykonania: %d\n", totalTests)
	fmt.Println()

	// Przygotowanie zada≈Ñ
	tasks := make([]TestTask, 0, totalTests)
	taskIndex := 0

	for _, n := range nValues {
		for test := 1; test <= testsPerN; test++ {
			// Zadanie dla scenariusza uporzƒÖdkowanego
			tasks = append(tasks, TestTask{
				N:       n,
				TestNum: test,
				Ordered: true,
				Seed:    int64(taskIndex * 12345), // Unikalny seed dla ka≈ºdego zadania
			})
			taskIndex++

			// Zadanie dla scenariusza losowego
			tasks = append(tasks, TestTask{
				N:       n,
				TestNum: test,
				Ordered: false,
				Seed:    int64(taskIndex * 54321), // Unikalny seed dla ka≈ºdego zadania
			})
			taskIndex++
		}
	}

	// Kana≈Çy do komunikacji
	taskCh := make(chan TestTask, 100)
	resultCh := make(chan TestResult, totalTests)
	progressCh := make(chan ProgressInfo, totalTests)

	// WaitGroup do synchronizacji worker√≥w
	var wg sync.WaitGroup

	// Uruchomienie worker√≥w
	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for task := range taskCh {
				result := runSingleTestThreadSafe(task)
				resultCh <- result

				// Wys≈Çanie informacji o postƒôpie
				progressCh <- ProgressInfo{
					Completed:   1,
					Total:       totalTests,
					CurrentN:    task.N,
					Scenario:    map[bool]string{true: "uporzƒÖdkowany", false: "losowy"}[task.Ordered],
					WorkerCount: numWorkers,
				}
			}
		}(i)
	}

	// Goroutine do monitorowania postƒôpu
	go func() {
		completed := 0
		lastReportTime := time.Now()
		startTime := time.Now()

		for progress := range progressCh {
			completed++

			// Raportowanie co 50 test√≥w lub co 5 sekund
			now := time.Now()
			if completed%50 == 0 || now.Sub(lastReportTime) >= 5*time.Second || completed == totalTests {
				percentage := float64(completed) / float64(totalTests) * 100
				elapsed := now.Sub(startTime)
				estimatedTotal := time.Duration(float64(elapsed) / float64(completed) * float64(totalTests))
				remaining := estimatedTotal - elapsed

				fmt.Printf("‚ö° Postƒôp: %d/%d (%.1f%%) | Czas: %v | Pozosta≈Ço: ~%v | Ostatni test: n=%d (%s)\n",
					completed, totalTests, percentage,
					elapsed.Round(time.Second), remaining.Round(time.Second),
					progress.CurrentN, progress.Scenario)
				lastReportTime = now
			}

			if completed == totalTests {
				close(progressCh)
				return
			}
		}
	}()

	// Wysy≈Çanie zada≈Ñ do worker√≥w
	fmt.Println("üì§ Wysy≈Çanie zada≈Ñ do worker√≥w...")
	go func() {
		for _, task := range tasks {
			taskCh <- task
		}
		close(taskCh)
	}()

	// Oczekiwanie na zako≈Ñczenie wszystkich worker√≥w
	go func() {
		wg.Wait()
		close(resultCh)
	}()

	// Zbieranie wynik√≥w
	fmt.Println("üì• Zbieranie wynik√≥w...")
	for result := range resultCh {
		if result.Scenario == "ordered" {
			results.OrderedResults = append(results.OrderedResults, result)
		} else {
			results.RandomResults = append(results.RandomResults, result)
		}
	}

	fmt.Println("‚úÖ Wszystkie testy wielowƒÖtkowe zako≈Ñczone!")

	// Obliczanie podsumowa≈Ñ
	results.Summary = calculateSummary(results, nValues)

	return results
}

// calculateSummary oblicza ≈õrednie dla ka≈ºdego n
func calculateSummary(results AllResults, nValues []int) Summary {
	summary := Summary{
		OrderedScenario: ScenarioSummary{AvgResults: make([]NSummary, 0)},
		RandomScenario:  ScenarioSummary{AvgResults: make([]NSummary, 0)},
	}

	for _, n := range nValues {
		// ≈örednie dla scenariusza uporzƒÖdkowanego
		orderedTests := filterResultsByN(results.OrderedResults, n)
		orderedSummary := calculateNSummary(n, orderedTests)
		summary.OrderedScenario.AvgResults = append(summary.OrderedScenario.AvgResults, orderedSummary)

		// ≈örednie dla scenariusza losowego
		randomTests := filterResultsByN(results.RandomResults, n)
		randomSummary := calculateNSummary(n, randomTests)
		summary.RandomScenario.AvgResults = append(summary.RandomScenario.AvgResults, randomSummary)
	}

	return summary
}

// filterResultsByN filtruje wyniki dla konkretnego n
func filterResultsByN(results []TestResult, n int) []TestResult {
	filtered := make([]TestResult, 0)
	for _, result := range results {
		if result.N == n {
			filtered = append(filtered, result)
		}
	}
	return filtered
}

// calculateNSummary oblicza ≈õrednie dla konkretnego n
func calculateNSummary(n int, tests []TestResult) NSummary {
	if len(tests) == 0 {
		return NSummary{N: n}
	}

	summary := NSummary{N: n}

	totalInsertComp, totalInsertPtr, totalInsertHeight := 0.0, 0.0, 0.0
	totalDeleteComp, totalDeletePtr, totalDeleteHeight := 0.0, 0.0, 0.0
	totalTime := 0.0

	for _, test := range tests {
		totalInsertComp += test.InsertAvgComparisons
		totalInsertPtr += test.InsertAvgPointers
		totalInsertHeight += test.InsertAvgHeight
		totalDeleteComp += test.DeleteAvgComparisons
		totalDeletePtr += test.DeleteAvgPointers
		totalDeleteHeight += test.DeleteAvgHeight
		totalTime += test.TotalTime
	}

	count := float64(len(tests))
	summary.AvgInsertComparisons = totalInsertComp / count
	summary.AvgInsertPointers = totalInsertPtr / count
	summary.AvgInsertHeight = totalInsertHeight / count
	summary.AvgDeleteComparisons = totalDeleteComp / count
	summary.AvgDeletePointers = totalDeletePtr / count
	summary.AvgDeleteHeight = totalDeleteHeight / count
	summary.AvgTotalTime = totalTime / count

	return summary
}

// saveResultsToJSON zapisuje wyniki do pliku JSON
func saveResultsToJSON(results AllResults, filename string) error {
	jsonData, err := json.MarshalIndent(results, "", "  ")
	if err != nil {
		return fmt.Errorf("b≈ÇƒÖd podczas konwersji do JSON: %v", err)
	}

	err = os.WriteFile(filename, jsonData, 0644)
	if err != nil {
		return fmt.Errorf("b≈ÇƒÖd podczas zapisu do pliku: %v", err)
	}

	return nil
}

// createAveragedResults tworzy skr√≥cony format z u≈õrednionymi wynikami
func createAveragedResults(results AllResults, nValues []int) AveragedResults {
	averaged := AveragedResults{
		AveragedResults: make([]AveragedResult, 0),
	}

	for _, n := range nValues {
		// ≈örednie dla scenariusza uporzƒÖdkowanego
		orderedResults := make([]TestResult, 0)
		for _, result := range results.OrderedResults {
			if result.N == n {
				orderedResults = append(orderedResults, result)
			}
		}

		if len(orderedResults) > 0 {
			avgResult := calculateAveragedResult(n, "ordered", orderedResults)
			averaged.AveragedResults = append(averaged.AveragedResults, avgResult)
		}

		// ≈örednie dla scenariusza losowego
		randomResults := make([]TestResult, 0)
		for _, result := range results.RandomResults {
			if result.N == n {
				randomResults = append(randomResults, result)
			}
		}

		if len(randomResults) > 0 {
			avgResult := calculateAveragedResult(n, "random", randomResults)
			averaged.AveragedResults = append(averaged.AveragedResults, avgResult)
		}
	}

	return averaged
}

// calculateAveragedResult oblicza ≈õrednie dla konkretnego n i scenariusza
func calculateAveragedResult(n int, scenario string, results []TestResult) AveragedResult {
	totalInsertComp, totalInsertPtr, totalInsertHeight := 0.0, 0.0, 0.0
	totalDeleteComp, totalDeletePtr, totalDeleteHeight := 0.0, 0.0, 0.0
	totalTime := 0.0

	for _, result := range results {
		totalInsertComp += result.InsertAvgComparisons
		totalInsertPtr += result.InsertAvgPointers
		totalInsertHeight += result.InsertAvgHeight
		totalDeleteComp += result.DeleteAvgComparisons
		totalDeletePtr += result.DeleteAvgPointers
		totalDeleteHeight += result.DeleteAvgHeight
		totalTime += result.TotalTime
	}

	count := float64(len(results))
	return AveragedResult{
		N:                    n,
		Scenario:             scenario,
		AvgInsertComparisons: totalInsertComp / count,
		AvgInsertPointers:    totalInsertPtr / count,
		AvgInsertHeight:      totalInsertHeight / count,
		AvgDeleteComparisons: totalDeleteComp / count,
		AvgDeletePointers:    totalDeletePtr / count,
		AvgDeleteHeight:      totalDeleteHeight / count,
		AvgTotalTime:         totalTime / count,
	}
}

// saveAveragedResultsToJSON zapisuje skr√≥cone wyniki do pliku JSON
func saveAveragedResultsToJSON(results AveragedResults, filename string) error {
	data, err := json.MarshalIndent(results, "", "  ")
	if err != nil {
		return err
	}

	return os.WriteFile(filename, data, 0644)
}

// printSummary wy≈õwietla podsumowanie wynik√≥w
func printSummary(summary Summary) {
	fmt.Println("üìä PODSUMOWANIE WYNIK√ìW")
	fmt.Println(strings.Repeat("=", 80))

	fmt.Println("\nüîµ SCENARIUSZ UPORZƒÑDKOWANY (Insert 1,2,3...n)")
	fmt.Printf("%-8s %-12s %-12s %-10s %-12s %-12s %-10s %-10s\n",
		"N", "Ins.Comp", "Ins.Ptr", "Ins.Height", "Del.Comp", "Del.Ptr", "Del.Height", "Time(ms)")
	fmt.Println(strings.Repeat("-", 80))
	for _, result := range summary.OrderedScenario.AvgResults {
		fmt.Printf("%-8d %-12.2f %-12.2f %-10.2f %-12.2f %-12.2f %-10.2f %-10.2f\n",
			result.N,
			result.AvgInsertComparisons,
			result.AvgInsertPointers,
			result.AvgInsertHeight,
			result.AvgDeleteComparisons,
			result.AvgDeletePointers,
			result.AvgDeleteHeight,
			result.AvgTotalTime)
	}
	fmt.Println("\nüü¢ SCENARIUSZ LOSOWY (Random insert)")
	fmt.Printf("%-8s %-12s %-12s %-10s %-12s %-12s %-10s %-10s\n",
		"N", "Ins.Comp", "Ins.Ptr", "Ins.Height", "Del.Comp", "Del.Ptr", "Del.Height", "Time(ms)")
	fmt.Println(strings.Repeat("-", 80))

	for _, result := range summary.RandomScenario.AvgResults {
		fmt.Printf("%-8d %-12.2f %-12.2f %-10.2f %-12.2f %-12.2f %-10.2f %-10.2f\n",
			result.N,
			result.AvgInsertComparisons,
			result.AvgInsertPointers,
			result.AvgInsertHeight,
			result.AvgDeleteComparisons,
			result.AvgDeletePointers,
			result.AvgDeleteHeight,
			result.AvgTotalTime)
	}
}

func runBenchmarkMain() {
	rand.Seed(time.Now().UnixNano())

	fmt.Println("üå≥ BST Performance Benchmark (WielowƒÖtkowy)")
	fmt.Println("===========================================")

	startTime := time.Now()
	results := runBenchmark()
	totalTime := time.Since(startTime)

	fmt.Printf("\nüéØ PODSUMOWANIE WYKONANIA\n")
	fmt.Printf("========================\n")
	fmt.Printf("‚úÖ Testy zako≈Ñczone w czasie: %v\n", totalTime)
	fmt.Printf("üîß U≈ºyto architektury wielowƒÖtkowej dla maksymalnej wydajno≈õci\n")
	fmt.Printf("üìä Przetestowano %d r√≥≈ºnych warto≈õci n\n", 10)
	fmt.Printf("üîÑ Wykonano %d test√≥w dla ka≈ºdego scenariusza\n", 20)
	// Zapis do pliku JSON - pe≈Çny format
	fullFilename := "bst_benchmark_results_full.json"
	fmt.Printf("\nüíæ Zapisywanie pe≈Çnych wynik√≥w do pliku %s...\n", fullFilename)

	err := saveResultsToJSON(results, fullFilename)
	if err != nil {
		fmt.Printf("‚ùå B≈ÇƒÖd podczas zapisu pe≈Çnego pliku: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Pe≈Çne wyniki zapisane pomy≈õlnie\n")

	// Zapis do pliku JSON - skr√≥cony format
	nValues := []int{10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000}
	averagedResults := createAveragedResults(results, nValues)
	shortFilename := "bst_benchmark_results_short.json"
	fmt.Printf("üíæ Zapisywanie skr√≥conych wynik√≥w do pliku %s...\n", shortFilename)

	err = saveAveragedResultsToJSON(averagedResults, shortFilename)
	if err != nil {
		fmt.Printf("‚ùå B≈ÇƒÖd podczas zapisu skr√≥conego pliku: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Skr√≥cone wyniki zapisane pomy≈õlnie\n")

	// Wy≈õwietlanie podsumowania
	printSummary(results.Summary)
	fmt.Printf("\nüìà ≈ÅƒÖczna liczba wykonanych test√≥w: %d\n", len(results.OrderedResults)+len(results.RandomResults))
	fmt.Printf("üöÄ Testy wielowƒÖtkowe przyspieszy≈Çy wykonanie!\n")
	fmt.Printf("üìÅ Plik pe≈Çny: %s\n", fullFilename)
	fmt.Printf("üìÅ Plik skr√≥cony: %s\n", shortFilename)
	fmt.Println("üéâ WielowƒÖtkowy benchmark zako≈Ñczony pomy≈õlnie!")
}
